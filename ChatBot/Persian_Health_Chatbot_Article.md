
### چت‌بات بهداشتی گفت‌وگوکننده با استفاده از یادگیری عمیق

این اسکریپت به منظور آموزش یک مدل شبکه عصبی برای چت‌بات بر تشخیص بیماری با استفاده از پردازش زبان طبیعی (NLP) طراحی شده است. این اسکریپت از کتابخانه‌های NLTK برای پردازش متن و TensorFlow/Keras برای ساخت و آموزش شبکه عصبی استفاده می‌کند.

این چت‌بات بهداشتی به صورت تعاملی علائم کاربر را دریافت کرده و بیماری محتمل را شناسایی می‌کند. می‌توانید این مدل را با داده‌های بیشتر گسترش داده و برای تشخیص بهتر استفاده کنید.

---

#### ۱. وارد کردن ماژول‌های مورد نیاز
ابتدا، ماژول‌های زیر را برای شروع فرآیند آموزش وارد می‌کنیم:

```python

import random
import json
import pickle
import nltk
from nltk.stem import WordNetLemmatizer
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.optimizers import SGD
import numpy as np

```

**توضیح مختصر ماژول‌ها:**
- **nltk:** کتابخانه پردازش زبان طبیعی (NLP) در پایتون.
- **WordNetLemmatizer:** برای لِماتیزه کردن کلمات (حذف تغییرات صرفی و بازگرداندن کلمه به شکل پایه).
- **Sequential:** مدل ساده شبکه عصبی برای استفاده در چت‌بات.
- **Dense، Activation و Dropout:** لایه‌های شبکه عصبی؛ *Dense* لایه کاملاً متصل، *Dropout* برای جلوگیری از بیش‌برازش، و *Activation* برای فعال‌سازی نورون‌ها.
- **SGD:** روش گرادیان نزولی تصادفی برای بهینه‌سازی مدل.

---

#### ۲. ساخت داده‌ها و ساختار JSON

برای داده‌های آموزشی از یک فایل JSON با ساختاری مشابه زیر استفاده می‌کنیم:

```json
{
  "intents": [
    {
      "tag": "نام بیماری",
      "patterns": ["علائم جداشده با کاما"],
      "responses": ["پاسخی که کاربر دریافت می‌کند"]
    },
    ...
  ]
}
```

- **tag:** نام بیماری.
- **patterns:** مجموعه‌ای از علائم بیماری.
- **responses:** پاسخ‌هایی که به کاربر نمایش داده می‌شود.

---

#### ۳. پردازش داده‌ها

اطلاعات JSON را به سه متغیر اصلی تقسیم می‌کنیم:
- **words:** برای ذخیره علائم.
- **classes:** برای ذخیره نام بیماری‌ها.
- **documents:** ترکیبی از علائم و دسته‌بندی مربوط به آن‌ها.


#### ۴. ذخیره داده‌ها با استفاده از **pickle**

برای استفاده‌های بعدی، کلمات و دسته‌بندی‌ها را در قالب فایل **pickle** ذخیره می‌کنیم:

```python
pickle.dump(words, open('words.pkl', 'wb'))
pickle.dump(classes, open('classes.pkl', 'wb'))
```

## فایل‌های مورد نیاز

1. `intents.json`: این فایل حاوی داده‌های آموزشی به صورت ساختار نیت‌ها (الگوها و برچسب‌های مربوطه) است.
2. این اسکریپت فایل‌های زیر را تولید می‌کند:
   - `words.pkl`: فایلی که لیست پردازش شده کلمات منحصر به فرد را در خود دارد.
   - `classes.pkl`: فایلی که لیست برچسب‌های نیت منحصر به فرد را در خود دارد.
   - `chatbot_model.h5`: مدل آموزش‌دیده که در فرمت HDF5 ذخیره می‌شود.

## عملکرد

### 1. **بارگذاری و پردازش داده‌ها**
- اسکریپت با مقداردهی و بارگذاری نیت‌ها از `intents.json` شروع می‌شود.
- هر الگو در نیت‌ها توکنایز می‌شود و کلمات منحصر به فرد شناسایی می‌شوند و همچنین نیت مربوطه (برچسب) نیز ذخیره می‌شود.

### 2. **نرمال‌سازی متن**
- **لوماتیزه کردن**: هر کلمه به فرم پایه‌اش تبدیل می‌شود.
- **شخصیت‌های نادیده**: برخی از نشانه‌گذاری‌ها مانند `؟`، `!`، `.` و `،` نادیده گرفته می‌شوند.

### 3. **نمایش Bag of Words**
- برای هر سند (الگو و برچسب) یک نمایش باینری Bag of Words ایجاد می‌شود.
- به این معنی که برای هر الگو، وجود هر کلمه منحصر به فرد با ۱ (وجود دارد) یا ۰ (وجود ندارد) مشخص می‌شود.
- تبدیل متون به نمایه‌های عددی است

### 4. **آماده‌سازی مجموعه داده**
- مجموعه داده به منظور اطمینان از تصادفی بودن قبل از آموزش، شافل می‌شود.
- سپس به ویژگی‌های آموزشی (`train_x`) و برچسب‌ها (`train_y`) تقسیم می‌شود.

### 5. **مدل شبکه عصبی**
- یک مدل Sequential ساخته می‌شود:
  - **لایه ورودی**: لایه Dense با ۲۵۶ نورون و فعال‌سازی ReLU.
  - **Dropout**: لایه Dropout با نرخ ۵۰٪ به منظور کاهش بیش‌برازش.
  - **لایه مخفی**: لایه Dense با ۱۲۸ نورون و فعال‌سازی ReLU.
  - **لایه خروجی**: لایه Dense با فعال‌سازی softmax، که معادل تعداد کلاس‌های منحصر به فرد است.

### 6. **کمپایل و آموزش مدل**
- مدل با استفاده از Stochastic Gradient Descent (SGD) به عنوان بهینه‌ساز و categorical crossentropy به عنوان تابع هزینه کمپایل می‌شود.
- مدل بر روی ۲۰۰ اپوک با اندازه بچ ۵ آموزش داده می‌شود.


- **learning_rate=0.01**: نرخ یادگیری را تعیین می‌کند، که سرعت به‌روزرسانی وزن‌ها در هر مرحله از آموزش را مشخص می‌کند.
- **momentum=0.9**: مقدار مومنتوم را تعیین می‌کند که به تسریع همگرایی و کاهش نوسانات در مسیر بهینه‌سازی کمک می‌کند.
- **nesterov=True**: فعال‌سازی نستروا (Nesterov) که یک تکنیک بهبود یافته برای مومنتوم است و پیش‌بینی بهتری از موقعیت آینده وزن‌ها ارائه می‌دهد.

### **template**
- اگر یک ورودی به یک کلاس خاص تعلق داشته باشد، می‌توان عنصر مربوطه در تمپلت را به ۱ تغییر داد. به عنوان مثال، اگر کلاس اول (نیت “greeting”) باشد، لیست به صورت [1, 0, 0] خواهد بود.


---

#### . آزمایش چت‌بات

کد زیر یک چت‌بات کامل است که با استفاده از ورودی صوتی، علائم کاربر را شناسایی کرده و پاسخ مناسب را ارائه می‌دهد:
کد ارائه شده شامل دو تابع است که به پیش‌بینی کلاس (intent) یک جمله و دریافت پاسخ مناسب بر اساس آن کلاس کمک می‌کند. در زیر توضیح مختصری از هر تابع ارائه شده است:

### تابع `predict_class(sentence)`

1. **ورودی**: یک جمله (string) به عنوان ورودی دریافت می‌کند.
2. **کیسه کلمات**: با استفاده از تابع `bag_of_words`، نمایه کیسه کلمات (bag of words) جمله را ایجاد می‌کند.
3. **پیش‌بینی**: با استفاده از مدل یادگیری عمیق، احتمال هر کلاس (intent) را پیش‌بینی می‌کند.
4. **فیلتر نتایج**: نتایج را بر اساس یک آستانه خطا (ERROR_THRESHOLD) فیلتر می‌کند تا فقط کلاس‌هایی که احتمال آن‌ها بالاتر از 0.25 است، در نظر گرفته شوند.
5. **مرتب‌سازی**: نتایج را بر اساس احتمال به صورت نزولی مرتب می‌کند.
6. **خروجی**: یک لیست از دیکشنری‌ها را برمی‌گرداند که شامل نام کلاس (intent) و احتمال مربوط به آن است.

### تابع `get_response(intents_list)`

1. **ورودی**: یک لیست از intents (کلاس‌های پیش‌بینی شده) به عنوان ورودی دریافت می‌کند.
2. **بررسی خالی بودن لیست**: اگر لیست خالی باشد، پیامی مبنی بر عدم وجود اطلاعات مرتبط برمی‌گرداند.
3. **انتخاب کلاس برتر**: کلاس (intent) با بالاترین احتمال را انتخاب می‌کند.
4. **پیدا کردن پاسخ**: برای کلاس انتخاب شده، از لیست پاسخ‌ها (responses) تصادفی یک پاسخ را انتخاب کرده و برمی‌گرداند.
5. **خروجی**: پاسخ انتخاب شده را برمی‌گرداند.
